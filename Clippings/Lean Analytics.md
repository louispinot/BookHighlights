#Lean Analytics
##Alistair Croll;Ben Yoskovitz
-----------------------------

**1074 (highlight)**

Pattern | How to think Like a Data Scientist Monica Rogati, a data scientist at LinkedIn, gave us the following 10 common pitfalls that entrepreneurs should avoid as they dig into the data their startups capture. 1. Assuming the data is clean. Cleaning the data you capture is often most of the work, and the simple act of cleaning it up can often reveal important patterns. “Is an instrumentation bug causing 30% of your numbers to be null?” asks Monica. “Do you really have that many users in the 90210 zip code?” Check your data at the door to be sure it’s valid and useful. 2. Not normalizing. Let’s say you’re making a list of popular wedding destinations. You could count the number of people flying in for a wedding, but unless you consider the total number of air travellers coming to that city as well, you’ll just get a list of cities with busy airports. 3. Excluding outliers. Those 21 people using your product more than a thousand times a day are either your biggest fans, or bots crawling your site for content. Whichever they are, ignoring them would be a mistake. 4. Including outliers. While those 21 people using your product a thousand times a day are interesting from a qualitative perspective, because they can show you things you didn’t expect, they’re not good for building a general model. “You probably want to exclude CHAPter 4: DAtA-DrIVen VerSUS DAtA-InForMeD 39 them when building data products,” cautions Monica. “Otherwise, the ‘you may also like’ feature on your site will have the same items everywhere—the ones your hardcore fans wanted.” 5. Ignoring seasonality. “Whoa, is ‘intern’ the fastest-growing job of the year? Oh, wait, it’s June.” Failure to consider time of day, day of week, and monthly changes when looking at patterns leads to bad decision making. 6. Ignoring size when reporting growth. Context is critical. Or, as Monica puts it, “When you’ve just started, technically, your dad signing up does count as doubling your user base.” 7. Data vomit. A dashboard isn’t much use if you don’t know where to look. 8. Metrics that cry wolf. You want to be responsive, so you set up alerts to let you know when something is awry in order to fix it quickly. But if your thresholds are too sensitive, they get “whiny”— and you’ll start to ignore them. 9. The “Not Collected Here” syndrome. “Mashing up your data with data from other sources can lead to valuable insights,” says Monica. “Do your best customers come from zip codes with a high concentration of sushi restaurants?” This might give you a few great ideas about what experiments to run next—or even influence your growth strategy. 10. Focusing on noise. “We’re hardwired (and then programmed) to see patterns where there are none,” Monica warns. “It helps to set aside the vanity metrics, step back, and look at the bigger picture.“


**1108 (highlight)**

fundamental challenge that Lean Startup advocates face: how do you have a minimum viable product and a hugely compelling vision at the same time?


**1176 (highlight)**

The sticky engine focuses on getting users to return, and to keep using your product. It’s akin to Dave McClure’s retention phase. If your users aren’t sticky, churn will be high, and you won’t have engagement. Engagement is one of the best predictors of success:


**1181 (highlight)**

The fundamental KPI for stickiness is customer retention. Churn rates and usage frequency are other important metrics to track. Long-term stickiness often comes from the value users create for themselves as they use the service. It’s hard for people to leave Gmail or Evernote, because, well, that’s where they store all their stuff.


**1186 (highlight)**

Stickiness isn’t only about retention, it’s also about frequency, which is why you also need to track metrics like time since last visit. If you have methods of driving return visits such as email notifications or updates, then email open rates and click-through rates matter, too.


**1191 (highlight)**

The key metric for this engine is the viral coefficient—the number of new users that each user brings


**1203 (highlight)**

Paid Engine The third engine of growth is payment. It’s usually premature to turn this engine on before you know that your product is sticky and viral.


**1212 (highlight)**

Revenue helps growth only when you funnel some of the money generated from revenue back into acquisition. Then you have a machine that you can tune to grow the business over time. The two knobs on this machine are customer lifetime value (CLV) and customer acquisition cost (CAC).


**1258 (highlight)**

The question this poses a of course, is how do you know if you’ve achieved product/market fit? Sean devised a simple survey that you can send customers (available at survey.io) to determine if you’re ready for accelerated growth. The most important question in the survey is “How would you feel if you could no longer use this product or service?” In Sean’s experience, if 40% of people (or more) say they’d be very disappointed to lose the service, you’ve found a fit, and now it’s time to scale.


**1291 (highlight)**




**1292 (highlight)**

Having reviewed these frameworks, we needed a model that identified the distinct stages a startup usually goes through, and what the “gating” metrics should be that indicate it’s time to move to the next stage. The five stages we identified are Empathy, Stickiness, Virality, Revenue, and Scale.


**1295 (highlight)**

We believe most startups go through these stages, and in order to move from one to the next they need to achieve certain goals with respect to the metrics they’re tracking.


**1300 (highlight)**

Ultimately, there are a number of good frameworks that help you think about your business. • Some, like Pirate Metrics and the Long Funnel, focus on the act of acquiring and converting customers. • Others, like the Engines of Growth and the Startup Growth Pyramid, offer strategies for knowing when or how to grow. • Some, like the Lean Canvas, help you map out the components of your business model so you can evaluate them independent of one another. We’re proposing a new model called the Lean Analytics Stages, which draws from the best of these models and puts an emphasis on metrics.


**1370 (highlight)**

Picking a minimal set of KPIs on which your business assumptions rely is the best way to get the entire organization moving in the same direction.


**1387 (highlight)**

you should use the One Metric That Matters. • It answers the most important question you have. At any given time,


**1391 (highlight)**

• It forces you to draw a line in the sand and have clear goals. After you’ve identified the key problem on which you want to focus, you need to set goals. You need a way of defining success. • It focuses the entire company.


**1471 (highlight)**

Optimizing your OMTM not only squeezes that metric so you get the most out of it, but it also reveals the next place you need to focus your efforts, which often happens at an inflection point for your business:


**1521 (highlight)**

More people means adding users, ideally through virality or word of mouth, but also through paid advertising. The best way to add users is when it’s an integral part of product use—such as Dropbox, Skype, or a project management tool that invites outside users outsiders—


**1529 (highlight)**

Early on, stickiness tends to be a key knob on which to focus, because until your core early adopters find your product superb, it’s unlikely you can achieve good viral marketing.


**1549 (highlight)**

The key here is analytics. You need to segment real, valuable users from drive-by, curious, or detrimental ones. Then you need to make changes that maximize the real users and weed out the bad ones. That may be as blunt as demanding a credit card up front—a sure way to reject curious users who don’t have any intention of committing or paying. Or it may be a subtler approach, such as not trying to reactivate disengaged users once they’ve been gone for a while.


**1579 (highlight)**

Not all customers are good. Don’t fall victim to customer counting. Instead, optimize for good customers and segment your activities based on the kinds of customer those activities attract.


**1814 (highlight)**

Accounting for the cost of acquisition in aggregate is fairly easy; it’s more complicated when you have myriad channels driving traffic to your site. The good news is that analytics tools were literally built to do this for you. The reason Google has a free analytics product is because the company makes money from relevant advertising, and wants to make it as easy as possible for you to buy ads and measure their effectiveness.


**1903 (highlight)**

In some cases, the unsubscribe rate caused by a bad email can overshadow any profit from the campaign, so email is a tool to use carefully.


**2008 (highlight)**

This means you have to know where the risk is, but focus, in the right order, on just enough optimization to get the business to a place where that risk can be quantified and understood.


**2011 (highlight)**

This is usually the right place to focus for SaaS companies, because they seldom get a second chance to make a first impression, and need users to keep coming back. In other words, they care about stickiness. The company will, of course, need some amount of conversion (and therefore some amount of attention), but only enough to test stickiness.


**252 (highlight)**

In this book we show you how to figure out your business model and your stage of growth. We’ll explain how to find the One Metric That Matters


**303 (highlight)**

A startup is an organization formed to search for a scalable and repeatable business model.


**384 (highlight)**

Instincts are experiments. Data is proof.


**475 (highlight)**

In a startup, you don’t always know which metrics are key, because you’re not entirely sure what business you’re in. You’re frequently changing the activity you analyze. You’re still trying to find the right product, or the right target audience.


**494 (highlight)**

Ratios are also good for comparing factors that are somehow opposed, or for which there’s an inherent tension. In a car, this might be distance covered divided by traffic tickets. The faster you drive, the more distance you cover—but the more tickets you get. This ratio might suggest whether or not you should be breaking the speed limit. Leaving our car analogy for a moment, consider a startup with free and paid versions of its software. The company has a choice to make: offer a rich set of features for free to acquire new users, or reserve those features for paying customers, so they will spend money to unlock them. Having a full-featured free product might reduce sales, but having a crippled product might reduce new users. You need a metric that combines the two, so you can understand how changes affect overall health. Otherwise, you might do something that increases sales revenue at the expense of growth.


**538 (highlight)**

One other thing you’ll notice about metrics is that they often come in pairs. Conversion rate (the percentage of people who buy something) is tied to time-to-purchase (how long it takes someone to buy something). Together, they tell you a lot about your cash flow. Similarly, viral coefficient (the number of people a user successfully invites to your service) and viral cycle time (how long it takes them to invite others) drive your adoption rate. As you start to explore the numbers that underpin your business, you’ll notice these pairs. Behind them lurks a fundamental metric like revenue, cash flow, or user adoption.


**550 (highlight)**

Exploratory versus reporting metrics Exploratory metrics are speculative and try to find unknown insights to give you the upper hand, while reporting metrics keep you abreast of normal, managerial, day-to-day operations.


**555 (highlight)**

Correlated versus causal metrics If two metrics change together, they’re correlated, but if one metric causes another metric to change, they’re causal. If you find a causal relationship between something you want (like revenue) and something you can control (like which ad you show), then you can change the future.


**595 (highlight)**

Another interesting metric to look at is “number of users acquired over a specific time period.” Often, this will help you compare different marketing approaches—for example, a Facebook campaign in the first week, a reddit campaign in the second, a Google AdWords campaign in the third, and a LinkedIn campaign in the fourth. Segmenting experiments by time in this way isn’t precise, but it’s relatively easy.* And it’s actionable: if Facebook works better than LinkedIn, you know where to spend your money.


**606 (highlight)**

better way is to run the four campaigns concurrently, using analytics to group the users you acquire into distinct segments. You’ll get your answer in one week rather than four, and control for other variables like seasonal variation. we’ll get into more detail about segmentation and cohort analysis later.


**631 (highlight)**




**636 (highlight)**

The “unknown unknowns” are most relevant to startups: exploring to discover something new that will help you disrupt a market. As we’ll see in the next case study, it’s how Circle of Friends found out that moms were its best users. These “unknown unknowns” are where the magic lives. They lead down plenty of wrong paths, and hopefully toward some kind of “eureka!” moment when the idea falls into place.


**684 (highlight)**

There’s a “critical mass” of engagement necessary for any community to take off. Mild success may not give you escape velocity. As a result, it’s better to have fervent engagement with a smaller, more easily addressable target market. Virality requires focus.


**722 (highlight)**

Lagging and leading metrics can both be actionable, but leading indicators show you what will happen, reducing your cycle time and making you leaner.


**732 (highlight)**

Finding a correlation between two metrics is a good thing. Correlations can help you predict what will happen. But finding the cause of something means you can change it. Usually, causations aren’t simple one-to-one relationships. Many factors conspire to cause something. In


**737 (highlight)**

So you’ll seldom get a 100% causal relationship. You’ll get several independent metrics, each of which “explains” a portion of the behavior of the dependent metric. But even a degree of causality is valuable. You prove causality by finding a correlation, then running an experiment in which you control the other variables and measure the difference. This is hard to do because no two users are identical; it’s often impossible to subject a statistically significant number of people to a properly controlled experiment in the real world.


**751 (highlight)**

recognize this: correlation is good. Causality is great. Sometimes, you may have to settle for the former—but you should always be trying to discover the latter.


**827 (highlight)**

A second kind of analysis, which compares similar groups over time, is cohort analysis. As you build and test your product, you’ll iterate constantly.


**827 (highlight)**

A second kind of analysis, which compares similar groups over time, is cohort analysis. As you build and test your product, you’ll iterate constantly. Users who join you in the first week will have a different experience from those who join later on.


**834 (highlight)**

You can compare cohorts against one another to see if, on the whole, key metrics are getting better over time.


**880 (highlight)**

This kind of reporting allows you to see patterns clearly against the lifecycle of a customer, rather than slicing across all customers blindly without accounting for the natural cycle a customer undergoes. Cohort analysis can be done for revenue, churn, viral word of mouth, support costs, or any other metric you care about.


**896 (highlight)**

A/B tests seem relatively simple, but they have a problem. Unless you’re a huge web property—like Bing or Google—with enough traffic to run a test on a single factor like link color or page speed and get an answer quickly, you’ll have more things to test than you have traffic.


**898 (highlight)**

You might want to test the color of a web page, the text in a call to action, and the picture you’re showing to visitors. Rather than running a series of separate tests one after the other—which will delay your learning cycle—you can analyze them all at once using a technique called multivariate analysis. This relies on statistical analysis of the results to see which of many factors correlates strongly with an improvement in a key metric.


**909 (highlight)**




